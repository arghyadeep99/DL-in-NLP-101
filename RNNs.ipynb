{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smlra-kjsce/DL-in-NLP-101/blob/master/RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIHn-Nt48DaN",
        "colab_type": "text"
      },
      "source": [
        "#RNN Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo5p5_408H8f",
        "colab_type": "text"
      },
      "source": [
        "##Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m93lvH8Bwa",
        "colab_type": "code",
        "outputId": "06abdd82-b458-45c3-a3de-5d65d7a6edc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "!wget http://cmshare.eea.europa.eu/s/6WZZ8dBECmER2EF/download"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 16:37:28--  http://cmshare.eea.europa.eu/s/6WZZ8dBECmER2EF/download\n",
            "Resolving cmshare.eea.europa.eu (cmshare.eea.europa.eu)... 87.54.7.179\n",
            "Connecting to cmshare.eea.europa.eu (cmshare.eea.europa.eu)|87.54.7.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cmshare.eea.europa.eu/s/6WZZ8dBECmER2EF/download [following]\n",
            "--2020-03-06 16:37:35--  https://cmshare.eea.europa.eu/s/6WZZ8dBECmER2EF/download\n",
            "Connecting to cmshare.eea.europa.eu (cmshare.eea.europa.eu)|87.54.7.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103636023 (99M) [application/zip]\n",
            "Saving to: ‘download’\n",
            "\n",
            "download            100%[===================>]  98.83M  10.5MB/s    in 11s     \n",
            "\n",
            "2020-03-06 16:37:48 (8.69 MB/s) - ‘download’ saved [103636023/103636023]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of2S2N1c8R-2",
        "colab_type": "code",
        "outputId": "76bae9a4-7863-4304-e509-d4b0916c3a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "!unzip download"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  download\n",
            "  inflating: BE_10_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_10_2013-2015_timeseries.csv  \n",
            "  inflating: BE_1_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_1_2013-2015_timeseries.csv  \n",
            "  inflating: BE_2013-2015_metadata.csv  \n",
            "  inflating: BE_20_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_20_2013-2015_timeseries.csv  \n",
            "  inflating: BE_3012_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_3012_2013-2015_timeseries.csv  \n",
            "  inflating: BE_3014_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_3014_2013-2015_timeseries.csv  \n",
            "  inflating: BE_3015_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_3015_2013-2015_timeseries.csv  \n",
            "  inflating: BE_3018_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_3018_2013-2015_timeseries.csv  \n",
            "  inflating: BE_4013_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_4013_2013-2015_timeseries.csv  \n",
            "  inflating: BE_5012_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_5012_2013-2015_timeseries.csv  \n",
            "  inflating: BE_5014_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_5014_2013-2015_timeseries.csv  \n",
            "  inflating: BE_5015_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_5015_2013-2015_timeseries.csv  \n",
            "  inflating: BE_5018_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_5018_2013-2015_timeseries.csv  \n",
            "  inflating: BE_5029_2013-2015_timeseries.csv  \n",
            "  inflating: BE_5_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_5_2013-2015_timeseries.csv  \n",
            "  inflating: BE_6001_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_6001_2013-2015_timeseries.csv  \n",
            "  inflating: BE_6015_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_6015_2013-2015_timeseries.csv  \n",
            "  inflating: BE_7013_2013-2015_timeseries.csv  \n",
            "  inflating: BE_7014_2013-2015_timeseries.csv  \n",
            "  inflating: BE_7015_2013-2015_timeseries.csv  \n",
            "  inflating: BE_7018_2013-2015_timeseries.csv  \n",
            "  inflating: BE_7_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_7_2013-2015_timeseries.csv  \n",
            "  inflating: BE_8_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_8_2013-2015_timeseries.csv  \n",
            "  inflating: BE_9_2013-2015_aggregated_timeseries.csv  \n",
            "  inflating: BE_9_2013-2015_timeseries.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNw9TxOA9BvQ",
        "colab_type": "code",
        "outputId": "8c19f750-97fb-4740-b4c2-a5430edca7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "import pandas as pd\n",
        "date_vars = ['DatetimeBegin','DatetimeEnd']\n",
        "\n",
        "df = pd.read_csv('BE_10_2013-2015_timeseries.csv', sep='\\t', parse_dates=date_vars, date_parser=pd.to_datetime)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Countrycode</th>\n",
              "      <th>Namespace</th>\n",
              "      <th>AirQualityNetwork</th>\n",
              "      <th>AirQualityStation</th>\n",
              "      <th>AirQualityStationEoICode</th>\n",
              "      <th>SamplingPoint</th>\n",
              "      <th>SamplingProcess</th>\n",
              "      <th>Sample</th>\n",
              "      <th>AirPollutant</th>\n",
              "      <th>AirPollutantCode</th>\n",
              "      <th>AveragingTime</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>UnitOfMeasurement</th>\n",
              "      <th>DatetimeBegin</th>\n",
              "      <th>DatetimeEnd</th>\n",
              "      <th>Validity</th>\n",
              "      <th>Verification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BE</td>\n",
              "      <td>BE.CELINE-IRCEL.AQ</td>\n",
              "      <td>NET-Brussels</td>\n",
              "      <td>STA-BETB004</td>\n",
              "      <td>BETB004</td>\n",
              "      <td>SPO-BETB004_00010_100</td>\n",
              "      <td>SPP-BETB004_00010_1</td>\n",
              "      <td>SAM-BETB004_00010</td>\n",
              "      <td>CO</td>\n",
              "      <td>http://dd.eionet.europa.eu/vocabulary/aq/pollu...</td>\n",
              "      <td>hour</td>\n",
              "      <td>0.165</td>\n",
              "      <td>mg/m3</td>\n",
              "      <td>2013-01-01 01:00:00</td>\n",
              "      <td>2013-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BE</td>\n",
              "      <td>BE.CELINE-IRCEL.AQ</td>\n",
              "      <td>NET-Brussels</td>\n",
              "      <td>STA-BETB004</td>\n",
              "      <td>BETB004</td>\n",
              "      <td>SPO-BETB004_00010_100</td>\n",
              "      <td>SPP-BETB004_00010_1</td>\n",
              "      <td>SAM-BETB004_00010</td>\n",
              "      <td>CO</td>\n",
              "      <td>http://dd.eionet.europa.eu/vocabulary/aq/pollu...</td>\n",
              "      <td>hour</td>\n",
              "      <td>0.165</td>\n",
              "      <td>mg/m3</td>\n",
              "      <td>2013-01-01 02:00:00</td>\n",
              "      <td>2013-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BE</td>\n",
              "      <td>BE.CELINE-IRCEL.AQ</td>\n",
              "      <td>NET-Brussels</td>\n",
              "      <td>STA-BETB004</td>\n",
              "      <td>BETB004</td>\n",
              "      <td>SPO-BETB004_00010_100</td>\n",
              "      <td>SPP-BETB004_00010_1</td>\n",
              "      <td>SAM-BETB004_00010</td>\n",
              "      <td>CO</td>\n",
              "      <td>http://dd.eionet.europa.eu/vocabulary/aq/pollu...</td>\n",
              "      <td>hour</td>\n",
              "      <td>0.175</td>\n",
              "      <td>mg/m3</td>\n",
              "      <td>2013-01-01 03:00:00</td>\n",
              "      <td>2013-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BE</td>\n",
              "      <td>BE.CELINE-IRCEL.AQ</td>\n",
              "      <td>NET-Brussels</td>\n",
              "      <td>STA-BETB004</td>\n",
              "      <td>BETB004</td>\n",
              "      <td>SPO-BETB004_00010_100</td>\n",
              "      <td>SPP-BETB004_00010_1</td>\n",
              "      <td>SAM-BETB004_00010</td>\n",
              "      <td>CO</td>\n",
              "      <td>http://dd.eionet.europa.eu/vocabulary/aq/pollu...</td>\n",
              "      <td>hour</td>\n",
              "      <td>0.165</td>\n",
              "      <td>mg/m3</td>\n",
              "      <td>2013-01-01 04:00:00</td>\n",
              "      <td>2013-01-01 05:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BE</td>\n",
              "      <td>BE.CELINE-IRCEL.AQ</td>\n",
              "      <td>NET-Brussels</td>\n",
              "      <td>STA-BETB004</td>\n",
              "      <td>BETB004</td>\n",
              "      <td>SPO-BETB004_00010_100</td>\n",
              "      <td>SPP-BETB004_00010_1</td>\n",
              "      <td>SAM-BETB004_00010</td>\n",
              "      <td>CO</td>\n",
              "      <td>http://dd.eionet.europa.eu/vocabulary/aq/pollu...</td>\n",
              "      <td>hour</td>\n",
              "      <td>0.150</td>\n",
              "      <td>mg/m3</td>\n",
              "      <td>2013-01-01 05:00:00</td>\n",
              "      <td>2013-01-01 06:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Countrycode           Namespace  ... Validity Verification\n",
              "0          BE  BE.CELINE-IRCEL.AQ  ...        1            1\n",
              "1          BE  BE.CELINE-IRCEL.AQ  ...        1            1\n",
              "2          BE  BE.CELINE-IRCEL.AQ  ...        1            1\n",
              "3          BE  BE.CELINE-IRCEL.AQ  ...        1            1\n",
              "4          BE  BE.CELINE-IRCEL.AQ  ...        1            1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPmnPSp1_OAW",
        "colab_type": "code",
        "outputId": "014b21b0-6d08-4ff6-ca98-85ce6df1e466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df['DatetimeBegin'][:100],df['Concentration'][:100])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
            "\n",
            "To register the converters:\n",
            "\t>>> from pandas.plotting import register_matplotlib_converters\n",
            "\t>>> register_matplotlib_converters()\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9eZxcZ3nn+31r7+rqRb2ope6W2pLV\nXmRLxlhYTrBMSAgYMrFJSGZMDIFclpBAyFySmZAJl2TIzUwCGcLNjJPgS5iBxGCWzGScYGxWx7LB\nxhK2JW9yt2QtraVX9Vp71Tt/nKVOV1d113LOqVPV7/fz6Y+6q+tUvTpd9avn/J7nfR4hpUShUCgU\nrYuv0QtQKBQKhbMooVcoFIoWRwm9QqFQtDhK6BUKhaLFUUKvUCgULU6g0Qsopq+vT15xxRWNXoZC\noVA0FUePHp2RUvaX+p3nhP6KK67gyJEjjV6GQqFQNBVCiDPlfqesG4VCoWhxlNArFApFi6OEXqFQ\nKFocJfQKhULR4iihVygUihanIqEXQtwuhDghhBgXQnx0nfu9TQghhRAHLLf9vn7cCSHEm+xYtEKh\nUCgqZ8PySiGEH7gH+FlgAnhKCPGAlPKFovt1AL8NPGm5bS9wF3AdMAh8RwhxlZQyZ99/QaFQKBTr\nUUlEfzMwLqU8JaVMA/cDd5a43x8DfwYkLbfdCdwvpUxJKV8BxvXHUygUCl66tMhTp+cavYyWpxKh\nHwLOWX6e0G8zEUK8GtghpfxGtcfqx79fCHFECHFkenq6ooUrFIrm5zPfHuM//M/jjV5Gy1N3MlYI\n4QM+DfxOrY8hpbxXSnlASnmgv7/kDl6FQtGCJLM5LsfTjV5Gy1NJC4TzwA7Lz8P6bQYdwPXAI0II\ngG3AA0KIOyo4VqFQbGLS2TwLiQxSSnT9UDhAJRH9U8CoEGKXECKEllx9wPillHJBStknpbxCSnkF\n8ARwh5TyiH6/u4QQYSHELmAU+JHt/wuFQtGUZHJ5MjlJIqPqM5xkw4heSpkVQnwIeBjwA5+XUj4v\nhPgEcERK+cA6xz4vhPgq8AKQBT6oKm4UCoVBOqfNrJ6PZ4iGPNdjsWWo6MxKKR8EHiy67eNl7vtT\nRT//CfAnNa5PoVC0MJlsHoCFRIbB7rYGr6Z1UTtjFQpFw8jkNKGfj2cavJLWRgm9QqFoGIbQLySU\n0DuJEnqFQtEwMrpHv6iE3lGU0CsUioaR0j36+YSqpXcSJfQKhaJhKOvGHZTQKxSKhqGSse6ghF6h\nUDQMFdG7gxJ6hULREKSUZjJWCb2zKKFXKBQNwRB5UELvNEroFQpFQzBsG1BC7zRK6BUKRUNI66WV\nQqhkrNMooVcoFA3BiOi3REMsJjPk83KDIxS1ooReoVA0hLQu9P2xMFLCUjLb4BW1LkroFQpFQzCS\nsf0dYUD59E6ihF6hUDQEw7pRQu88SugVCkVDMJKxfbEQoPrdOIkSeoVC0RBURO8eSugVCkVDKET0\nmtCrEkvnUEKvUCgagpGMNYReRfTOoYReoVA0BMO66YgECAd8aviIgyihVygUDcGoow/6fXS1BZV1\n4yBK6BUKRUMwIvpwwEd3NKisGwdRQq9QKBpCpjiiV+WVjqGEXqFwiO+8MMmDxy82ehmeJZPVkrHB\ngCb0C4lCC4SnTs/xxR+ebszCWhAl9AqFQ/ztY6/w14+cbPQyPEvKjOgFXW2hVcnYz/7LKf7zgy8h\npWp0ZgdK6BUKh0jn8qykVaOucmT0OvqQmYwtWDfHJuZJZHIspdT5swMl9AqFQ6SzeeKpXKOX4Vms\nHn13NMhKOkcml2dyMcnUUgqAqcVkI5fYMiihV9TEf/7mi3zmOy83ehmeJpXNNSSiPzm9zBv/4l84\nOxt3/bmroTgZC9qmqWMTC+Z9JhdTDVlbq1GR0AshbhdCnBBCjAshPlri9x8QQhwXQjwjhHhMCLFX\nv/0KIURCv/0ZIcTf2P0fUDSGH4zP8oOTs41ehqdJZ/PE0znXfeajZy7z8uSy55OZaX1nrObRF4T+\n+MS8eZ9JFdHbwoZCL4TwA/cAbwb2Am83hNzCl6SU+6SUrwI+CXza8ruTUspX6V8fsGvhisaSzuZJ\nZZQtsR7pbJ5cXpLK5je+s41cmE8A8LWjEyQ9/DfK5PKE/D6EEHRFNaGfj2d4dmKBnT1RQEX0dlFJ\nRH8zMC6lPCWlTAP3A3da7yClXLT82A6oVHmLk87lSXhYRLyAsfNzxeWE4sX5JEJo0fE3jnm3vDOT\nzRP0CwAzol9MZDh+foFbdvcQCwdURG8TlQj9EHDO8vOEftsqhBAfFEKcRIvoP2z51S4hxNNCiH8R\nQhyqa7UKz5DK5Ehm3I1Umw0jko+n3f1AvLCQYP9QF7v727nvyTOuPnc1pHN5ggFNgrp1oX/h4iJz\nK2n2DXcz0BlmakkJvR3YloyVUt4jpbwS+D3gY/rNF4GdUsobgY8AXxJCdBYfK4R4vxDiiBDiyPT0\ntF1LUjiIiug3xhD6ZZcj+vPzCYa2tHH3wRF+fHaeFy4sbnxQA8jk8gT9mgQZEf2jL2vv/xuGuxjo\njCjrxiYqEfrzwA7Lz8P6beW4H3grgJQyJaWc1b8/CpwErio+QEp5r5TygJTyQH9/f6VrVzSQVDbv\naf+30UgpzX7rcRcrb6SUXJhPMNjVxttePUQ44PNsVJ/OSkJFQv/js5cJ+gVXb+vQhV5F9HZQidA/\nBYwKIXYJIULAXcAD1jsIIUYtP/4cMKbf3q8ncxFC7AZGgVN2LLwVWUllm2bLfFoJ/boYvdYBVlys\npb8cz5DM5BnsbqM7GuLnbxjkH58+z1LSew3DtIhe8+gDfh+xcIBMTnLNtk7CAT9bO8NMLabU7lgb\n2FDopZRZ4EPAw8CLwFellM8LIT4hhLhDv9uHhBDPCyGeQbNo3qXffhtwTL/968AHpJRztv8vWoR/\nPnaB37zvx5zXqya8ipSSdC5PJifJ5pRPX4q05by4GdEbFTeD3W0A/MKNQ6ykczx9dn69wxpCJpcn\nFChIkBHV7xvuAmCgI0I6l+eyal9cN4FK7iSlfBB4sOi2j1u+/+0yx/0D8A/1LHAzYbRpnY+nGdLf\nqF4kk5MYQVYymyfmV/vuiklbSiqXXYzoDaE3Xj/Gv9NL3vO6rR49aEJ/fl5LJAMMdEYArZa+pz3U\nkDW2Cuod6iEMQVhKeru/hzVaVfZNaVLZwnlpRES/vVsTSWPw9syy94Q+nZNrhB4sEX2ntnbl09eP\nEnoPYdRbe17oLdFqwuXSwWbBeo7c9OgvLCQJBXz06hFwezhAW9DvTaHP5sxkLEB3NEg44OOqgQ6g\nENFPqcqbuqnIulG4Q0Hove1JWkXMGrkqCqwWevc+uM/PJxjqbkMIYd7W1xHyqHUjiQQLQv+Lrx5m\n/3C3GeUbVyMqoq8fJfQeYrkpI3qVjC2Fte2Bm43NLswnGNRtG4O+WJiZZe9Nb8rk8nREChL0s3sH\n+Nm9A+bPkaCfLdEgk2rTVN0o68ZDNEtEb43ikyqiL8mqqhuXk7GDXasT+ZrQey+iT2dXJ2NLoTZN\n2YMSeg+x0iTJ2JTy6DckZWkPsexSRJ/J5ZlaSrG9qGKrv8ObQl9cXlmKrZ0R1ZPeBpTQewjTuvH4\nVB1VdbMxqyN6d/6elxaSSAlDJayb2ZW05/Y8ZHJyVTK2FAMdYRXR24ASeg9heLlej+hXefRK6Eti\nnKP2kJ8Vl656ijdLGfTHQkgJc3Fv+fTWnbHlGOiMML2cIpdXu2PrQQm9h2gWj35V1Y3qYFkS4xxt\naQ/ZWkefzuYZm1wq+bsLC6WFvi+m19IveUvoK/Pow+TyktkVFdXXgxJ6D9EsVTcpFdFvSDqnnZee\n9pCtdfRfOXKON33mUcan1or9hXnNy16TjPXopql0bmOh32rsjl3w1tqbDSX0HiGby5v93Zspolce\nfWmMK53uaMjWOvoXLiyQl3Dfk2fX/O78fIKe9hBtIf+q2/tj3hT6SpKx1jYIitpRQu8RrD6u1yN6\nI1oFFdGXw0jG9kSDtg4eGZtcBuAfjk6sqXi6OJ9ge1dkzTFGRO+1TVOZnKzAo9c3Tala+rpQQu8R\njKivPeT3vtCviuiVR18K4xx1R0OspLO2tNqVUjI2tczVAx0sJrP807ELq35/YT65xp8H7TUVCfo8\nFdHn8pJcXhLy+9e9X38sjBDemx379aMTXFzwdpdZK0roPYIh9Nu6Iiynsp6uMlDWzcYYeYwtUa3i\nxY4rn+nlFAuJDHfdvIPRrTHue2L1QJELevuDYoQQntsdm9GveIKB9SP6gN9HXyzsqVr65VSW3/3a\ns3z9yESjl1IxSug9gpGI3a4n0tweP1cNhoi1Bf1K6MtQqLrROjLakZAdn9Jsm9GtHdx9cCfPTixw\nfGIBgMVkhqVUdk37AwOv7Y41hH6jOnrQ7BsvefTzeplqvIle+0roPYIhBIbH6uWErCH0XW1B5dGX\nIZXNE/L7aA9pvVzsSMiaQj8Q4xdePUxb0G+OCSxXQ2/Q3xH2lEdvfBBuVHUD2gASL1k3xtyIZtoV\nrpqaeYRCRG8IvXcjeuNN2tkWUBF9GdJZraKkPawLvQ219GOTy3REAmztCCOE4I4bBvmHH09w9Mxl\nM+G7vau00PfFwjx99nLda7ALY9RiJUK/tTPCM+e8MyHLEPpmeu0rofcIBY9ee6N6Wuj1HY1toQAJ\nlYwtSTqX04VeSzbaUXkzNrXEnq0xswXxb77+ShKZHNm89je47ao+rh/qLHlsfyzE3EqaXF7i963v\ni7uB6dFvUHUD0NMeZCGRQUq5qv1yo1jQRxs209WsEnqPsDai97B1k9Fsibagr6miGjdJ69ZN1Gbr\n5qev2Wr+PNLbzl++/caKju3rCJOXMLeSNvu8NxKj/HSjOnqAWDhINi9JZfNEgutX6bhBM1o3yqP3\nCMuWqhvwekSvRasRlYwtSzqbJxz0ETOsmzqTsZdX0swspxnd2lHT8X0e2zRVTTI2pves98p7whT6\nJnrtK6H3CCupLH6foDemjYDzcgdLw39WVTflSZkRvRaB1uvRj09ridg9A7Gaju/32KapTLZyj75D\n/7D0SiXafBN69EroPcJKKkt7yE9nRCvH87J1Ywh9JOhvqqjGTYqTsfW2KjZ2xO7pr03ovRbRp806\n+o0lyDiHyx6L6Jtps6ASeo+wnMoRCwcIB3wE/cIzl6mlSOfyhAN+3bppnhe7m6Rz+VXJ2HpbFY9N\nLdEW9JfcEFUJffqVomeEPlt5Mtawv5ZS3gh+mjEZq4TeI6yksrSHAwgh6IgEPR3RG8nYSNBHsokS\nUm5iWDchv4+AT9SdjB2fWmbP1hi+GitmjCDCK7tjq/HojbmyXovoVTJWUTUr6ax5idoRCXg+ojc9\nejUztiRaMtaPEIJoyF93eeX41DKjW2uzbaDQBsEzHn2u8g1TMY959M1YR6+E3iMsp7LmC9rrQp+y\nePSZnPTciDovYET0oHnM9YjUUjLDxYVkzYlYAy/Njs1UU14Z8ZbQzye0qyJl3SiqRrNuND+3I+xt\n6yadzRMOaNYNQDKrhL6YdDZHOFAQ+nqmTBmtD2pNxBp4KaJPV7Ez1vToPRL8WD16O7qSuoESeo+w\nkso1j3WjC32bvnmlmbxKt0hbhmq0h/x11dGPmT1uaquhN+jvCHnHo89W7tEbBQpeiOhzecliMkvI\n70PK1dPWvIwSeo+wnMqa9cJaMrbxL+pypLLahqmwLvTN5FW6Rdpi3URD9UX0T5+9TEc4wI4ttVXc\nGPTFwsyteGPQdqVtikHLL8TCAU8kY40r7YEurVy1WV77FQm9EOJ2IcQJIcS4EOKjJX7/ASHEcSHE\nM0KIx4QQey2/+339uBNCiDfZufhWQUppVt2AFtEvetm6yRktEJTQl8PYGQuGR1/bOZJS8ujLM/zE\nlb0EKoh+16MvVmiD0GjSVSRjQfPpvRDRG4nY7Z3ah26z+PQbnmUhhB+4B3gzsBd4u1XIdb4kpdwn\npXwV8Eng0/qxe4G7gOuA24G/0h9PYSGVzZPNS1PoO/UXdd4DkVcprBumoLk2jrjF6mSsv+aI/vRs\nnPPzCQ6N9tW9Ji9tmqqmTTFo/W68cJU7Hzcieq1VSbPYlpWc5ZuBcSnlKSllGrgfuNN6BynlouXH\ndsBQqDuB+6WUKSnlK8C4/ngKC0aNtZF0ikUCSFndtvmFeIY773mc8aklR9ZoRfPo/QWPvkmiGjcx\nPgxBs24q8ej/19MTvPu//2jVB/zhsWkADo32170mow3ClAcSskab4ko8etDaINg5ZL1WjIh+mz7L\ntlle+5Wc5SHgnOXnCf22VQghPiiEOIkW0X+4ymPfL4Q4IoQ4Mj09XenaWwZDBNotHj1UV2Vw7Pw8\nz56b55g+cchJChG9XnXTJC92t8jnJdm8NIU+FvZXJFL/9OxFHjkxzaNjhffA4bEZdvS0MdIbrXtd\nVw904BNw9Ezj+9JXU14J3rFujD43RjvxZnnt25aMlVLeI6W8Evg94GNVHnuvlPKAlPJAf3/9kUuz\nsWxG9Hp5ZQ11w2fn4oA9fc83IlVk3TRLVOMWxS14o6EAiUxu3SSolNL8kL7vybOAJoY/PDnLodF+\nW/qwd0WD7B/uNq8SGkkml8cnqLg3fqzOvQh2UYjoDeumOWzLSoT+PLDD8vOwfls57gfeWuOxmxLD\nolkb0VeekD07awi9s28GM1r1Wz16JfRWjJK7cEA7P8b+iPU+EC8uJJlZTjHQGea7L05yYT7Bs+fm\nWU5lObSnfn/e4LbRPp49N2/WgjcKbXhN5XFmzCMlx4tmRN961s1TwKgQYpcQIoSWXH3AegchxKjl\nx58DxvTvHwDuEkKEhRC7gFHgR/Uvu7UwIhVr1Q3AYhUv7DO60NsxhHo9rNFqW0gJfSlSeluIkGXD\nFKw/fMSI5v/g5/YigfufOsejYzP4BPzklfYJ/aGr+slL+OGpGdsesxYyWVmxPw9GRN/4SrT5eJpI\n0EdXmxaMNYvQbzhhSkqZFUJ8CHgY8AOfl1I+L4T4BHBESvkA8CEhxBuADHAZeJd+7PNCiK8CLwBZ\n4INSyuY4My5i1AfHLFU3UJ1Hf0a3bpx+4RWiVR+RgOHRN8flq1sYFSVho+qmgilTx8/PE/AJ3rh3\ngNdd1c/9PzrLtq4IN+zopisatG1tr9rRTSwc4NGxGW6/frttj1st6VyuohbFBrFwgGQmT6bKKwG7\nWUhk6G4LFa5mm6TqpqJRglLKB4EHi277uOX7317n2D8B/qTWBW4GVtZE9NVZN1JKzs0ZEb2zl7dp\ni9AbEX2zRDVuYZyjgke/8dzYYxMLXL2tg0jQz90HR3jfF48wtZTiwz+9x9a1Bf0+btndy2NjjY/o\nK2lRbBCzXBV1R0NOLWtD5uMZutqCTVdxpmbGegAzGRtabd0YEX0yk+MrT50zLYG2UIC7XrPDjGzm\nVtLmYzhd12u1JSIBZd2UojgZu5F1I6Xk+PkF3nz9NgB++pqtDHZFuLCQ5NBV9hcnHBrt4zsvTnJm\ndoWR3nbbH78Sqo3MreMEGyn0Cwld6JvMtlRC7wEK5ZXai6ct6MfvE2ZE/8CzF/jDB55fdcz2zghv\n2DsAFGwbqH9k3UZYo1WfTxAK+JomqnEL61UPWIS+zN/m3FyC+XiGfUPdgFaJ8r7bdvP5x1/hVTu6\nbV+fsfnq0bEZ3tkgobf2AqoEr4wTXEhk2NETNYOcZnntq143HmAlnSUc8Jlb3LXhI4Uqg8NjM/R3\nhHnuP76Jox97Az4Bx84X6uWNipuOSMDx8kozWvVrL/RIwEdKefSrSBVZN+3G3NgyifJj5+cB2D/c\nZd72a6/dxeF//9OO+NG7+toZ6m7jsQaWWWZy+eqSsR5pVWxE9D6fINxEQY4Seg+wnMqado1BLKwJ\nfT4veWxsmkOjfcTCAXpjYa4a6ODYxLx5X6OG/uqBDueFvihabQv5m2YbuFukizozRo25sWUi+uMT\nC4T8Pq6qsztlpQghODTaxw/GZxs2SyCTk9VZNx6ZG6slY7UcWlvI3zTJWCX0JfjSk2f51vOXXHs+\na0MzA2Oc4PMXFrkcz6zqdbJvqIvjEwtmL+wzs3G2dUboaQ+5low1otXIOlOmHn7+Ep/+9stN07Pb\nLorPkZF7KdfY7NjEAtdu76jKyqiXQ6P9LKWyPGsJGNxE8+grT8aaeasGRvTpbJ54OmeWVrYF/Sqi\nb2b+9rFTfPXIuY3vaBMrqaxZgmegdbDMcnhcu7x+rWXTzP4d3cyupLmwkATg7NwKO3ujREPOv/CK\nbYm2YPmI/u9+eIa//O4Yn330lKNr8hprzpFRdVNCpPJ5yXPnF9g/bL8Xvx6v2qk934lLy64+r0Eq\nW2UyNqyJayMjemNXbHfUKvTNYVsqoS9BKpt3daCAdYygQafu0R9+eYZrt3eytSNi/m7/kOblHjun\nRWNnZuPs7IkSDVfWPKseiqPVcNBfdsLU2NQSAZ/gzx56ie+9NOnouryEkccwdsaGAtqQ8JUSH4iv\nzK6wlMqyz+LPu8FARxi/T3BhPuHq8xpkqkzGGh59IxubGULfqUf0kXWCHK+hhL4EyUze1QSjNl1q\ndffmjkiQ6aUkR87MrWlRe832DoJ+wbHzCyTSOaaWUoz0RIkGa2+HWympIv+5Legr6VMuJDJMLqb4\nzdfvYe/2Tn77y8+40lnTC6T0q6qwRcjayzQ2O67viN3vstAH/D62dUYaKvTVRPTRoB8hGmvdLOiz\nYrusHr2ybpqXVDZn1ou7QWmPPsDMcppMTq4R+nDAz9XbOjg+scC5y1oidmevFtEnMjlH+9gb0arR\nubKcR2/MOd0/1MW9v3qAcNDH73z1WcfW5SWK6+hBb1Vc4kP42MQCkaCv7nmwtTDYHeF8o4S+yhYI\nPp8gFmrslKmCdaPV8SuPvsnxgnVjJJ/CAR+vuaJnzTH7hro5NjHP6ZkVAEZ622kP+ZGSsslROyhU\nlBRq/ktdvp4055zGGOpu444bhjg1veLYurxEcdUN6MNHSthqY1NLXDXQUff0qFoY7G7jwkIDI/oq\nk89aq+LG9bsxho50Keum+cnnJWmXhb5c1Q3Azbt6zL4aVvYPd2nJWn0r+0hP1Nxq76RPX9ywq1xE\nPza1RDjgY3iL1kc9FgmwnPbu1Cw7Kc5jQPmIfmxymT1b3Y/mQRP6SwvJhsyQTVdZdQONb1VsRvTK\numl+jMvulEt/wHxespLOlbRugLIj5AxP95vPXaQjHKA7GiSqV+44GWWUKq8s1ZN7bGqZ3f0xs994\nR1ibmhV38Lx6JQdQvNcANJEq9ugXkxkuLSYbKvSZnGzIaMFqN0yBtsO4ka2Ki5OxbUG1YappMZKw\nbkX0hvDFipKxg91t+AS8/uqtJY+7akCru55ZTrOzN4oQohDRO5iQLRaxSNBX8kNxbHKZUYuAmTsb\nHXqjPj4+wxs+/SjffqHx1T2prDZUw2rHdEQCXC7qAW/kMUa3urNRqphBfe5pIxKy6SrLK0E7h42M\n6OfjGToiATN4UR59E2PYEG4JfXHnSoOfuqqfR//96xkts1sy6Pexd3sngDlmrrAD0+WIvujFHk9n\nOT+fWC30Zq8SZzzW7700BcAXf3jakcevhlJ9XK7e1sHp2ZVVQlUQ+sZF9AAX5pOuP3e1O2NBt24a\nGNEv6u0PDCJNtCtcCX0RhYjenT9gYYzgaqEXQpj+djkM+2Znj9aYqt1sh+tgRJ/LIwQELFFNNi/N\nGaAAJ6e0pOvowFqhd+rS+/DYNEJofYGMBHWjSGfX2hI3DHcjJTxn6VE0PrVMKOBjR0/982BroSD0\nDYjoc3mCgeby6OeLhT7gJ5XNN0XeSQl9EYbAZ3LSlSSVGdGHqm8kuk/fOGVE9G2uJGM1ETNmmJYa\nED6me+V7LJaEk02pJheTvDy5zK/95C78PsGXf3TW9ueoBm2m7mor7nr9b3XcMrx9bHKJKy15DLfp\njASIhQOul1hKqQUG4Woj+kj1Ef1KKsvf/fC0LW04FhIZc1csFN5vTla52YUS+iKs05LSLtg3ZkQf\nqV7obx3tY3dfu1l+aXxYJDLOevRWW6LNnBtbOFdjU8sEfML8AAJnm1IZlUdvu2mIN+4d4KtHzjW0\nGiKdza9KxAL0d4QZ7Iqs6jo6NrXcMNsGtKvGwW73N03l8hIpqd6jD1dfuXX/U+f4f/7387x0qf5E\n/UJRRG8OH2kC+0YJfRFWy8YN+6Z4jGA1bO9q43u/+1Nm1YY75ZV5c2s/aC0QYHVEPz61zK6+9lVv\nZNO6cSCiPzw2TV8sxLXbOrn74AiX4xkees69pnTFpLK5NUIPsH+4m+N6EzEjj9GoihuDRtTSZ3Ka\nUNdSR19t5dZhvRWzHZahNl2qMPTEDHJcLMWuFSX0RViTsG4kZI0KmeJkbC0YyVinyyvDJSP61UJv\n9eehUC5qd0Sfz0seH5/h1j19+HyCn7yylyt6o/z9E2dsfZ5qKL7qMdg33MXp2TgL8QynpleQsnGJ\nWIPB7jYuupyMNUqYq0/GVtfYLJXN8eSpOe2YOosApJQlk7GgIvqmxCpYbvS7WS6aLlUPhug6Wl5Z\nVFESKZqdmczkODO7ssqfh8IHmd0e/YuXFplZTnNoVBu55/MJ7j44wpEzlxmbbExdfbnpSUby/Pj5\nBTOPUfyB6DaDXRFmV9KuWl2FncNVJmMj1VVuHT1z2Xxd1hvRJzI50rl8SeumGTZNKaEvYnVE7/wf\nMJGuPRlbjN8niAR9jpZXpjK5VRUlxR79KzMr5EtEqkG/j0jQZ7vQG0Oub7VsLHvd1Zrov2iDL1sL\npapuoJA8P3Z+nrFJI4/RmFF+Bo2ovMnUGNEXxglW9vo+bBmAXu/rbuKydn4GuwtdZJtpQLgS+iJW\nRfQuWDfGrtJSbQ5qoT0UcLy8cnVEr31vvNiN2vBS3nMsHLS9vPLw2AxXD3Qw0Fl4A/a0az7qXAN2\nfIJubwXXvrW6oyFGeqMcn1hgrEQeoxE0opa+VqGvdtPdY2MzXDfYWdUx5RibXPu6bgvpr31l3TQf\nbkf08Yw2L9auEru2UOnmWXZR7NFHii5fx6aW8QltLmkxHZG1bQDqIZnJ8aPTa9s4b4mGEALmVtK2\nPVc1pMpE9KBF9ccmFjg51drYBEUAACAASURBVLgeN1aGGhjRVztRq5pNd3MraZ67sMAb927DJ+qP\n6MemlhACrrR0GS22Lb2MEvoiUi579Ml0zqzHtQMtondW6Et59IbQn7i0yEhve8krlFo3vDw+PsMN\n//FbLBS1EPjxmcuks3leWyT0fp+guy3IXLwxQl8uGQuaT39+PsErsysNT8QCDHRGEAJXa+nTWb3q\npoadsVCZ3/74+AxSwm1X9Znzl+thbGqZnT3RVa9r5dE3MUmXq27i6Zz5grGDaNjvajLW3DSSyZHL\nS544NceBkS0lj611C/uLFxdZSGQ4ObN67N3p2cJQ9GJ62kMNi+i1c1T6b2qMDJQS9rg0DHw9QgEf\nWzvCDYroq7uK7ahi093hsWk6IwH2D3fTEQnWHdGPT67d89Cmqm6aF2sU70oyNmNvRB8N+R1Oxq62\nJSKBgk95/PwCC4kMh67qL3lsezhQUx39ot41sFiMLswn8PsEWzvCa47paQ8xu9zAiL5MtHrdYCf6\npmJPRPSgl1gueN+jb69w052UksNjM7x2Tx9+n6i7R042l+eVmRWuLBZ6Zd00L6s3TLmRjLU5onfa\nuikX0WfzPKZvTnntlb0lj+2ocXDEfDmhX0gw0BEuObSjkRF9qkwyFrQ5A7v72svmMRrBYFebqxG9\nUV5ZrdAH/T7CgY0rt05Or3BxIWmW3LbXeZV7di5OOpdf02VUefRNjHUrvxsefSKTM3e02oEW0Tvb\nAsG6MzYSKFy+Pjo2w/VDnfTG1kbYULt1s2AK/eqo88J8wqwaKaanPdxAoc+t22v9tXv6uH6oy7ZK\nq3oxRgra0Q+mEmrdMAVasLDeVaGUkk9/+wQ+ofnzALFIfdVeY2W6jIYDPoSg5Mxkr1HRmRZC3C6E\nOCGEGBdCfLTE7z8ihHhBCHFMCPFdIcSI5Xc5IcQz+tcDdi7eCVLZnHlp7ZZ1Y+cbPhoKON/UzBLR\n+3yCUMDH7EqKH5+5bEZRpYjp/cSrFRRjhNta6yZZVuh720Ncjqcb0lmwVK8bKx/7ub185f0/4eKK\n1mewu41UNu/aB6PRAqHawSOwcbDwX783zoPHL/H7b77W7P7aUWfXS6NkuNi6EUI0TU/6Dc+0EMIP\n3AO8GdgLvF0Isbfobk8DB6SU+4GvA5+0/C4hpXyV/nWHTet2jFQ2b27McMu6sTOibw/5zU1YTpAu\n0cclEvDxyIlpsnnJoT2lJ2KB9ibN5GTV59WM6C09WfJ5ycWF9SL6EHlZsH3cQkpZdmesQSjgszUv\nUy9u19LXWl4JhWChFA8/f4lPf/tlfvHGId57aFfhmDo9+vGpZQa7IiX7UbWM0AM3A+NSylNSyjRw\nP3Cn9Q5Syu9LKeP6j08Aw/Yu0z2SmZw5KswVoc/Y7dH7iWdyjl2GF0f0oPn0E5cTRII+brqidMUN\nVFc1YWWxhHUzs5wik5MMWXYqWumN6ZumVtzdNJXVOzPWEq02CqOW/tzl+Ab3tIdCMrb6vSPlRHt8\napmPfOUZbtjRzX/6xX1mG21Y/8OhEsamlspWSJUbpek1Knk1DgHnLD9P6LeV4z3ANy0/R4QQR4QQ\nTwgh3lrqACHE+/X7HJmenq5gSc6RyuaJhQMI4c7c2Hg6R5sN7Q8Movps1qQD+QUzWi0SMcN6umV3\n7yr/vphaWxUbUfncStosZTPqvteL6AHXK2/MUYtlkrFeZHd/O73tIf78WydYTDp/BVRrMhb03dUl\nRPuvHzmJEIJ733nTGivU2L9Ri42Xz0utSV+ZCqlI0Lf56uiFEO8ADgCfstw8IqU8APwK8BkhxJXF\nx0kp75VSHpBSHujvL+/xukEqmycS9BMO+FxpP5q0ueqm3cG5sUa0WmzdGOu/dR3bBqw7Gytfm5SS\nhUSmsINTt2+McsDtXesL/WWXN02lzIZdzSP00VCAv7r71ZydjfPhLz/t+MAd06OvwbopVbk1H0/z\nz8cu8As3Dq1qhWE9Bmp7T5yfT5DM5MsKfVuodayb88AOy8/D+m2rEEK8AfgD4A4ppXm9LKU8r/97\nCngEuLGO9TpOMqN50OGA3/GIXkpJPJMze2bYgXF14EQbhOJ5sQZGT/rbytTPGxi9SqqpgFhOZcnl\nJddu1y6djYSs8e9Q2WSsVvkz63LlTeEceceDr4SDu3v5ozuu45ET03zy4Zccfa60XuRQW0S/1rr5\n+tEJUtk8v3JwZ9ljoLY2CBt1GW0LNsfc2ErO9FPAqBBilxAiBNwFrKqeEULcCHwWTeSnLLdvEUKE\n9e/7gNcCL9i1eCewRvROe/TGuMKojdaNOTfWgSlT5YS+LehjoDO84QagDqOfeBVvOCMRawxCNwT+\n/HyC9pCfzrbS525Lu/Zccw2ybmqJVhvNO24Z4e6DO/nsv5zi0Zeds1DNwSO1ePQRrZ2B0Q5DSsmX\nnjzLTSNbuFZ/jZQ6BiqzDF+ZWeGX/voH5sASs0lf/zoefR0B4We+8zL3fH+85uMrZcNXo5QyC3wI\neBh4EfiqlPJ5IcQnhBBGFc2ngBjwtaIyymuBI0KIZ4HvA38qpfS20BsRfdB5oTciATvLK52cG5sq\nI2IffP0e/t+3rk6AlcJ4w1XT2MwQ+qu2dSBEISFr1NCXe85wwE8sHHA/os9p570ZhR7g4z+/l4BP\n8MSpWceeo546+tuv24YQ8KEv/5hsLs8PT85yamaFd9xSOpqHyqebLSYzvPcLT3HkzGV+874fc2p6\nmbHJZfo7wnRZZsVaaQv66/Lov3HsIv/49BqDxHYqCiWllA8CDxbd9nHL928oc9wPgH31LNBttF2N\nfs26cbiO3ogEbC2vdHDKVLqM/7xe7byVWsYJGpFbb3uYgY6IxbopX0Nv0IjdscaH4Xp19F4mHPAz\ntKWNs3POVeCY5ZU1CP0NO7r54zuv56P/8zh/+s2XuLCQYEs0yJuv3172mEqmm+Xykn97/zOcmY3z\nX375Bv7kwRd57xePEPT51r1SbQvVJ/STi0lS2TxSyg0DpXqwzzNoEVKZHJGAttXa6Z2xhtDbXV4J\nziRjjWg1XON6a6m6MSL67miQ7d0RSzI2wfX6II9yNFLomzWiB9jZE3Vc6AM+ga/G1tx33byTFy8u\n8rnHXkEIeN+h3eteFccqsAz//Fsn+N5LU/zxW6/nbTcNM7SljXd87kmyecm7do+UPa6eOvpEOsei\n/l6YWkqVTCTbRfO+Gh0iqfcpccOjN1oV2NvULLDqse2k3oqSSFDru19NvxujtLKrLagNsp5Pkszk\nmFlOM9i1/hujtz3UsGRsuImqbooZ6Y1yZtZJoZd1D1z52L/ay0/s7kUAb7+5vG0DhTGd5QKMFy4s\n8tePnOTtN+/kHXpC9xY9OQ1wTRnvH4w6+tqEfmqpsC/EyfMNKqJfg+bRu2PdJB2I6M1krIPWTa22\nhBDVdxK0RvRD3W18+4VJ076pxLp57sJCTWutlWZOxhqM9LSzkMiwEM+U9abrIZ3N15SItRL0+/j8\nu1/DmbmVDZvDGUUA5SzD75/Q6kc+8rNXrbJP3nHLCNdu7+C6wfJXjpp1U1tAeGnBKvQr3Lyrp6bH\nqYTmfTU6hFZ1404y1hBjOz164+rAifJKO2yJWJWtiufjGYJ+rafIYFeEdDbP8fOaeG8o9LEQl1cy\nrjXrgtYQ+p29Wo+YM3Mrjjz+Ri0iKqUt5OeabeWjbYONIvrDY9Ps3d5Jf4l21zeN9KxrC7UF/aRz\nebK56rVicqmwa9tJqwyU0K8im8uTzUs9onfBo3eg6qZg3Xgvogd9w0uVEX1XWxAhhCnsR05fBsrX\n0Bv0todI5/K2DyRfD6OiZL0dwl5nZ48u9A7ZCZls3tVZuQG/j7agv6RluJLKcvTM5TXjKCvFnDJV\nQ1A4tahF9F1tQcetGyX0FoyINRL0uVp1Y6dH7/cJIkGfIx69HdFqteMEF3Whh0IEf+TMZYSAga7S\n7ZANevRNU24mZI3XTFNH9LrQOxVlZnLuCj0Y/W7Wvp9/9MocmZysuHKsmEgdU6YmF5NEgj6uH+pU\nEb2bFErj3NkwlXDAutEeL+BQ1Y0NQl9lg6n5RHqN0L90aZH+WHjDqLnX6HfjotC3gnXTHg7QFwtz\n1qmIPiddPz/lWhU/OjZNOODjwDrN+Najnrmxk4tapc3OnnYl9G5i/LHc2jBl2Ct2JmPBuXGC5ero\nq6GWZGx3VBPsLdEgkaAPKWH7BrYNFPrduLk71o5z5AVGeqOOevQNiehLNGw7PDbDzbvW9+HXo55x\ngpOLSQY6Ioz0RplbSbPkYEO55n412kzBuvG70uvGCesGdKF3JBlbvy2x0YSgYubjBevG6tOXa09s\nxRR6V62b5o/oAUZ6og5G9HlCdVbdVEspy/DiQoLxqWVuq9G2Acw+VbVYN1NLKbZ2hhlxOCcCSuhX\nYQhZOOBOHX0incMn7I/+HLNusvUnGmuJ6A2hh0ICdrBM10orPY2wbnL1J6y9wI6eKBcXk47kqZJ6\nCbObxMKBNc30Do/NAHBrjYlYsIzSrDIolFJqEX1nhB0O50RACf0qjHrYsJ6MzeZlTWVTlaLNiw3Y\nvvW5PexMRz17yiuDJDK5is5rLi9ZSmZXCb0h8BuVVoJ2ZRMO+FwdPmJUarWCdSMlnJuzf2h4PJ0j\nGnZZ6Evkhg6PzdAXC3PNttINyyrBTMZWKfTLqSzxdI5tnZp1A0roXcOwaiIBvzk4Iu2w0DsxILot\nGGDFCY/ehmjVqGmuZH2Lll2xBobAVyL0Qgh620PMrbg3TlDzn2vf3u8VCuJjv08ft3l8ZiUUJ2Pz\necnj4zPcNtpXV6BlJmOrfL9NLmrBx9bOMB2RID3tIWXduIVRC2u0QAAcraW3e16sgRbRO9ACwYZo\ntZpxgtZdsQZDWwyPfmOhB23TlNMR/f/9lWf4Tw++CGj2VrNH8wA7e7Tdpk749PFU1tbW3JUQ0/dv\nGJvnXry0yNxKui7bBlYnY+fjae74b49x35NnNjxuUq+hN/rbaP2FnEl+g2qBsIqUWXXjNyNtJ336\nhM3TpQyiIb9jEX09zajA0mCqAp9+vkRE/5Z920hlc1w/tPGOSNBq6Z1Mxi4lMzzw7AX8PsFvvO5K\nTeib3J8H6IuFiIb8nHHATlhJ58xWHW7RHg6QzUtz3oTRZ36jxngbYRRSLKeyfOhLT3NsYoHhLW3c\nfbB8IzRYK/QjvVGOnrlc11rWo/lfkTayesOUHtE7uGkqnsmZHp+dREMB4g7sBk1n83UnGc0hEBU0\nNisV0UdDAe4+OFLx5bbTjc1+eHKWXF6Szub5+tEJ/Rw1765YAyGEFmU6ENEnbJ6TXAkd4dXTzYz/\nl7E5rFaMgPCe74/z2PgMW6KV7XI1rRu97cJIT5QL8wmz4MFulNBbSFoieuPN6mREn0zniDoQ0beH\n/MQzOdt7vNgRrcbClY8TXCgR0VdLcavic3NxW2eiHh6bIRryc8OObr70o7Mks7mWiOhBE0FrRH9x\nIVF34JPJ5Unn8q5H9LEiy/DMXJyBznDdOTLjinxyMcWvvfYK7rhhkLOz8Q3fe5OLSTrCAXN+xI6e\nKHlZmKBmN63xirQJ69AINzz6eCZrew09aHNjpaTmrnrlsEPoq/Lo9cHenXUKfTydI5nJ8c/HLnDo\nk9/noecu1fx4xTw2PsMtu3t590+O8MrMCo+Pz7aM0I/0an3p83nJ0TOXed0nH+FvH3ulrsc0Nwm6\nLfRFluHZ2Xjd0Txo4xA7wgFu3dPHH7zlWnb0RFlKZbkcX/+KdWopydbOQguPkV4tJ+KEVQZK6Fdh\nCn2wUHXjpHWjXcI6k4wF+3vSp2yIVqsZPmJHRG+0QTg8NsPvfu1ZoOCP1su5uTivzKxwaLSPN1+/\nnS3RIDPLqZZIxgLs7G0nnc3zzMQ8v/53R0nn8kwt1pfYNl6TRiTrFoXpZtpr6szciplwrgchBN/4\n8CH+9t0HCPh9BcGeXT+xarQ/MDCrnDY4rlZa4xVpE6taILhg3TiVjDUe0+42COlc/RUlxZfQ6zEf\nz9AW9NfleW/Rhf7DX36a7rZQxc9dCY+NaxtuDo32Ewn6+eUDO4Dm3xVrYOzYfN8XjpBIZ+kosemo\nWoxZxq6XV1rGCSYzOSYXU6a41svO3qj5Gq20Jt7YLGWwtSNMJOhzrMSyNV6RNlHSunEyos84VV6p\nD+G2OaK3I9HYHqrOo++uc/CFEdHnpeT//9UDertae87L4bFptndFuLJfi+KMSUfNvivWwBCtuXia\nz9x1I4PdbVVNBytFoZFfYyL65VSWc7oI2yX0VszOn+sItpSSqaKI3kh+K+vGBVLZHOGADyFEwbpx\nso4+41x5Jdgf0ads8Oj9PkF7qDKxLW5/UAu7+2MMdkX4L//6BvYNd9FuQ1QK2q7dx8dnOWTZcLOr\nr51fvHGI/cP1lex5haHuNvZsjfH7b76Gn907UHXn0VIYwUcjk7FnbKq4KUUk6GegM7yuYM/HM6Rz\neQY6V7fZ3tnTzuyyM3s+VB29hVSmUD7otHWTz0uSmbwjHr05fMTmxmZ21YjHKhw+Mp/I1JWIBS0Z\n+4Pf/xnz5w4bxArg+PkFFhIZbi1qiPXpf/Oquh/bKwT8Pr7zkdeZP7eHA2aCvFYSDUvGWoTejOjr\n9+hLsVFZ6qWiGnqDe+6+0bHSXBXRW0hlc4T1CNsQ/Fr6TFdCMutMi2KwRvR2J2Prr6OHyoePLCYy\ndNcp9CWf24Z2sIdfnkYIuHVPfTsrm4lyPd2rYaVBydhwwEfQL1hOZjk7u0IsHGCLA/NwQYvM12vx\nXNgstTqid3L/hRJ6C6mMNi8WsHj0zkT0TpaZRS279ezEru391rmx33r+Ev/ua8+W/EC1tii2i1g4\nYCYE6+Hw+AzXD3aZHTI3A9VOBytFvEHJWHMwvR7R7+yJ2t5M0GCkN8rkYqpskDhlbpbauNW2XSih\nt5DMFtqnhs0WCM5E9AmHho6A1vCrMxLg+yembX3ceDpL1IZILBYJsJLKcmxint/68tN87egEH/2H\nY2s2mdiRjC313NX0wy9FPi957vwCN43UNpWoWanUclsP4yrT7WQsFNZ/di7uSCLWwHjsc2V8eiOi\n39q5/ihMO1FCb2G1R+9sMtapoSOgJYTedtMwDz13kRkbkzuLySxdbTYIfTjAhfkEv/53R+mLhXnf\noV384zMXuPfRU+Z9UtkciUzO9ohesx/qs24uLiaJp3OMDsRsWlVzEAtrXVHr2Vm84tD4zEpoDwVY\nSGSYmEuw00Gh32i4+uRSki3RoKutMpTQWzAaHgFa8y7hnHXj1LxYg7sPjpDJSb565JwtjyelZDGR\noTNSv/DGwkEuLiSZj2e491dv4j+85Vp+bt92/vShl3jkxBRgz2apks9tQ1Q6NrkEwOjW2vuYNyNG\nLXo9ZbvGsJ1GlKB2RAKMTy+TzuUZsWGzVDlMoS8b0afWJGKdRgm9BW3yjXZKhBDaOEGHrBvDo3ei\nHz3Anq0xbtndw5eePEveht4uiUyObF7WXQUDhSZlf/7LN3DdYBdCCD71y/u5dlsnv/Xlpzk5vVzo\nRR+11wM3fNp6+gAZnQ/3bN18ET1Utqu5HCvpLO0ODNuphFg4YEbZTlo3Pe0hYuFA2V2uU4tJ+jvc\ns22gQqEXQtwuhDghhBgXQny0xO8/IoR4QQhxTAjxXSHEiOV37xJCjOlf77Jz8XZjjegBRweEG4ka\nJ73Kd9wywsTlBP8yVr9Xv5jQ3tx2RPTvuXUX/+PXXsPP7d9u3hYNBbj3V28i6Pfxvi8eMScbORHR\nZ3Kyrr/r2OQyve2hTZWIhep2NZcj0YDpUgYxy2vXiRp6A7PzZ5mIfnop5WoiFioQeiGEH7gHeDOw\nF3i7EGJv0d2eBg5IKfcDXwc+qR/bA/whcBC4GfhDIYRnM1jWiB60y0vHPXqHInqAN+7dRl8sxH1P\nnK37sRb1ksROGzz6we42furqrWtuH94S5a/vfjVnZ+P83j8cA7C9vLIjXL9YjU8vb7poHqrrPFqO\nlXSuIYlYKKw/4BNs73JWaEd6S+9ylVIys5ymr8PdIKGSiP5mYFxKeUpKmQbuB+603kFK+X0ppfG/\negIY1r9/E/BtKeWclPIy8G3gdnuWbj/FdeJuWDdOJqVCAR//+sAOvvfSJOfrbH9qWCl2RPTrcXB3\nL390x3VMLWlJZCcieqjdfpBSMja5tOkSsVBd59FyaNOlGhPRG+sf3tJGwOHGczt7o0zMJdYkrhcT\nWdK5PP0x71k3Q4A1ozeh31aO9wDfrOZYIcT7hRBHhBBHpqftLQmshlR29QzXcMA568aI6J3y6A3e\nfvNO8hK+efxiXY9TiOidFXrQLKd33jJCOOCjz2Yv02xXW6NYTS+lWExm2dO/+YS+mulg5WjEvFgD\nI6Lf6dCOWCs7e6Kkc3lzF6zBtF4F50mPvlKEEO8ADgCfquY4KeW9UsoDUsoD/f39Gx/gEMlMUUTv\noEdvzHR1eiv4jp4oQ91tPDuxUNfjFDx6dy67P3Hndfzw93/GfHPaRb32w5ieiB0d2FwVN1DddLBy\nxNPuz4s1MP72Iw768wZGVU9xu2Kj3LnPgxH9eWCH5edh/bZVCCHeAPwBcIeUMlXNsV7B2gIBnLVu\nEmntA8RJj95g31AXxyfm63oMNyN60BJaTiQ7Y3V69EbFzajy6Gsins6Z8xLcxvigcrLixqDcpikv\nC/1TwKgQYpcQIgTcBTxgvYMQ4kbgs2giP2X51cPAG4UQW/Qk7Bv12zyHlPrgYJeSsfFMllDAh7+O\nQduVsm+4i9OzcRY2mHqzHoZH3+FSRO8U9UalY1NLdEYCrl96ewFD6OtpIRFP52gLNuY1ZCTinay4\nMdjeFSHgE2s2Tc0sGULvsWSslDILfAhNoF8EviqlfF4I8QkhxB363T4FxICvCSGeEUI8oB87B/wx\n2ofFU8An9Ns8RzqXR0qKInoHyytd9CpvGO4GtI6LtbKYzOpD05t78HW9teBjk8uMDnQ0pA680fh9\ngmjIX5d1s5LONiyiv36oixuGu7hxp/OFfwG/j6EtbZy7vLoIYno5hd8n2GLz/pAN11PJnaSUDwIP\nFt32ccv3b1jn2M8Dn691gW5hHTpi4HTVjRu2DWjWDcCx8/PcOlpbt0W7dsU2GuOKpNZ+N+NTy7zh\n2gE7l9RU1NvYLO7Q+MxK2NET5X9/6FbXnm+wq42LRdVuM0tpettD+Fy4kreidsbqGBZN2KUNU4mM\ney/4rmiQkd4ox+tIyC4m7e8k2QjCAR8Bn2ClBrGaW0kzu5LelKWVBrFI7YNbsrk86WzenDLW6mzv\njnChWOiXU67786CE3sQ6L9bA0Q1TLkb0oEX1x+oQ+gUbhoB4ASFEzf1uNmvrAyv1RPTxTOMamjWC\noe42Li0myeYKGjKznLK9ZLgSlNDruG3dODUvthw3DHdzfj5RczfLxUTWtdJKp7H2w6+GsSm9mdkm\nLK000Aa31Cj0qcbMi20Ug91t5CVMLhXeczPLadcTsaCE3sQQdDc3TDm9WcrKPn2Oaa0J2cVka0T0\nULtYjU0u0x7yM+jw9nkvU09EX5gutTki+sHuNgDTvpFSMr2Ucn1XLCihN0lm1kb0kaDf0TbFblo3\n1w12IgQ1+/StkoyF2ufGnpxe5sqtsU1ZcWNQj0fv5LAdLzLUrQUEhtAvJvX2B8q6aRxGRG8tHwwH\nfOTycpXHZhduWzcdkSC7+9pr8umllCwms7Y0NPMCtUSlmVye5y8sbroe9MXUMzfWSIC7PS+2UWzv\nMiJ6rQ1CozZLgRJ6EyPpasyMBa3qBpwZPtKIMrMbhrs5VsMO2bg+VahVIvpYJFi1dfPdFyeZW0nz\nln3bHFpVcxCL1N7Pf7MlY9vDAbqjQTOiL2yWUkLfMEpH9MbcWPuFPtmAHYL7hruYWkqZMysrxe32\nB05TSzL27584y1CZ9sqbiVg4SC4vTauzGjZbMha0qN4QeqOhmdstikEJvYlZdRNcXV6p/c7eyhsp\nJfFMjraQu6d/v56Qrda+sXPoiBfo2KC88olTs8xaqpNemVnhsfEZ3n7zDldaVniZmLnhrPrdsSvm\nYPDNEdGD5tOfL4roVTK2gSRLtA02rRuba+kzOUkuL12PbPZu78LvE1XbN3YOHfEC7aGANhqxRO4l\nk8vzzr99krs/9yRxXZi+9OQZAj7Bvz6wY839NxsddfS7cXpOshcZ7C5E9DPL6Ya0PwAl9Cbl6uit\nv7OLhMPzYsvRFvIzujVWQ0TvztARtzCi0lJiNb2UIpOTvHRpid/92rMkMzm+dnSCN143wFaXBzp7\nkXp6BRXKK1sjYKiEwe42FpNZlpIZZpZT9DSg/QFU2OtmM1BIxq6uugH7rZtEA5NS+4e7+M6LU0gp\nKy4TbDWP3ohKl1IZuqKr/09G/uLQaB8PHr/E9NKTzMczvOPgyJrH2YzUY90k0jl8YnUw1eoYtfQX\nF5INa38AmyCil1LyF99+eUO7onQLBL/+O5sjehfmxZZj33A3cyvpqkYLuj10xGnWG3I9uaj5qL93\n+zX8wo1DPHX6Mrv72vmJK3tdXaNXqSuiT2nzYjfTPgRrLf30Uqohu2JhE0T0Pz57mf/vu2McOTPH\nfe+9pez9Utk8PqENDjYolFfaG9Eb3q/b1g3Afr2T5fGJBYa3VNaX27RuWiSiX0+sppa0iH6gM8J/\n/sV9ALz5+m2bSpzWo565sdp0qc3jz8PqWvqZ5TRXNqhPUstH9H//xFkAHh+f5dT0ctn7GfNirW9o\n07qxOaJPNtC6uWZ7B0G/4FgVrRAWkxmiIT9Bhwcqu0VsnVbFk4tJ/D5Bb3uISNDPX/ybV/HG6zZ3\n7byVeiZ0adOlWj62XMXWjjB+n+D8fJzp5ca0P4AWF/q5lTTfOH6Rt+zbRsAn+NKTZ8vet3heLDiX\njI0bW8EbIPThgJ9rtnVWVXmjNTRrjWgerJUjpa2brR3hhiTMmgHzQ7IG6yaezm6a9gcGAb+PbZ0R\nTlxaJp3NK4/eCb5+xjfoGAAAEqxJREFU9BzpbJ5/+4areNN12/ja0Qkzmi4mlc2tmZ5USzL27354\nmt/4+6Pr3qfRPT/2DWstiyvd3ai1KG6dSMz06EuI1eRiUlXXrEM44Cfk99UR0W8uoQcY7I6YgVUj\nNktBCwt9Pi/50pNnufmKHq4a6ODuW3aykMjwjWMXS94/lc2van8AtbVAeODZC3zzuUtmpUopzGRs\ng/zK/UNdLCWza+ZZlmMx2ToNzWB9+2FqMcXAJpwHWw219vNfSedo20S7Yg0Gu9uYamD7A2hhoX/8\n5AynZ+PcfctOAH5idy+7+9v5+yfPlLx/MlMqotetmzJXAcXk8pLnzi8C8Nw6teqN3jhitCyu1Kdv\npRbFgDnhqJT9MLmUZEBF9OtSa6vieCpL+yZLxkKhxBJo2FD5lhH6TC7PM+fmza+/fewVetpD3H69\nlkgTQnD3wRGePjvP8xfWClwqm1/V/gCs1o0W0S8kMqueY24lver+J6eXzWh9PRGNN9i6uWqgg3DA\nx7Fzlfn0rTR0BMDnEyXFKpnJMR/PMNCpIvr1aA/X1qo4ns5tqj43Blahb1RE3zJnfTGR4a33PL7q\ntg+87spVUfrbXj3Enz30El8/OsF1g12r7pvM5IiU9eg1oX/P/3iKI2cum7+/brCTb3z4kPmzseM0\nHPCt2/fdEJhGWTdBv4+9g52bNqKH0sNHpvQaehXRr4/Wqrj6DVObsbwSMAfV+AQNaX8ALST0sUiA\n//7u15g/+3yCg7t6Vt2nOxri4K4eDo/NrDk+lc2b3q1BwO/D7xOksjmev7DAkTOXec+tu7h1Tx/f\nfWmSv3/iLJOLhUv94xPztIf83HZVP8fOl4+WJy7H6YuF11hFbrJ/qIuvH50gl5frNuqSUrbU0BGD\nWInhI5OWGnpFeWKRANNL1Y+kjKdzRDdlMlaL6Hvaww1ritcy1k044Of112w1v153VX/JDUm3jfYz\nPrW8Zjp7qkR5pfa42oDw+548SyTo48M/Pcrrr9nKr9ysbYm3fmg8O7HA9UNdvGpHN+fmEmusHYMz\ns3FGeivbrOQU+4a7WUnneGWm/N4C0BJoedk6Dc0MSrUqNtofKKFfn1o8+mwuTyqbJ+pya24vYAh9\no3bFQgsJfaUcuqoPgMeKovpkNke4xAdDOOBjdiXNPz59np/fP2j2RrlmWwd9sRCHx6YBLUfwwsVF\n9g93bTif9dxcnJGexgq90bL4L787zn/73hj3fH+csyWqcFqtoZmBZt2sth8mTetGefTrUTxO8PHx\nGU7PrKx7jDF0ZDOWV3ZGAsTCgYYlYmETCv3VAx30d4Q5PF4Q+oVEhgvziZK71sIBPw89d4l4Osc7\nbik0tvL5BLfu6ePx8RnyecnLk0uks3n2DXdzvdlmYK19k8rmuLiYZEeDhf7K/hgjvVEeePYCf/6t\nl/nUwyf4r98bW3O/VmtoZlAqKp1aTBIK+Ohqsf+r3Vg9+mQmx3u+8BR/8Z2X1z2mUGm2+SJ6IQSv\n3dPLgZGeje/sEJvurAshOLSnj0deniafl/h8gv/54wmSmTy/dNPwmvuHgz4SizmuH+o0o2CDW0f7\n+cdnLvDipUUz+bp/qIvOdeaznptLICUNt278PsH3f+enyOmbpt77hSMlr0CMhmatJn6lasG1fEtY\n9bXZgFg4QDKTJ5PLc/TMZZKZPC9PbmABpjbf0BErn33ngYY+/6aL6EGzb+ZW0rxwcREpJfc9eZYb\ndhQicSuGb3/3wZE1AnBotGADPTuxQGckYAq4sfu0mLNz2iVuo4UetKuSoN9H0O/jhuEuXp5cMiMv\ng1a2btZ69CkGOpQ/vxGFfv5ZHtWty5PTy+Ty5Xdaxzfh0BEvsSmF/rV7NIF+dGyaJ1+ZY3xqmbsP\n7ix533DAT0c4wB03DK753UBnhKsGYhwem+H4+Xn2D3ebHwb7h7u5tJhkqmg+q7EbdWdPu53/pbrZ\nN9xNXsILF1d/OLXadCmDjhJDrtVmqcowqtOWklkOvzyDEJDO5jk3V36ndXwTWzdeYFMK/daOCNds\n6+CxsRnue/IsnZEAP79/rZADvP3mnXzsX11btuveodF+fnR6jhOXlswkLBSSncV2yJnZONGQv6EZ\n+FKUmyfbyhG9lAUBAq2OfqtKxG6I0ar4zGycFy4u8jPXaAPTx6bK2zdGa+7NWF7pBSoSeiHE7UKI\nE0KIcSHER0v8/jYhxI+FEFkhxC8V/S4nhHhG/3rAroXXy6HRPo6cvsxDz13kbTcNl9289CsHd/Jv\nXlM62jceJ53Nk8lJs9c7wN7tnfjEWuE8NxdnZ0/Ucz7wQGeErR3htUKv+9gdLbQzFtYOH1lOZVlO\nZdmmIvoNiYW1D/2Hntf6Rr37J3cBML6u0OtVNyqibwgbCr0Qwg/cA7wZ2Au8XQixt+huZ4F3A18q\n8RAJKeWr9K876lyvbRwa7Sed0wS6nG1TCQd39RLS+7RbI/r2cIA9W2Nr2gGf0YXei+wf7l6z3oVE\nhvaQn0CL9KI3KG5spmroK8f4kHzouUm62oL8xJW9bOuMMDa1VPaYzZ6MbTSVvHtvBsallKeklGng\nfuBO6x2klKellMcAexu3O8jNu3oIB3zcsruHPVs7an6ctpCfA1dsobc9xJClpwXAvqHuVe2A83nJ\n2bnGb5Yqx/7hLk7NrLBkqS9fTLRe+wOwTEpKrhZ6Zd1sjPEhObOc4tY9ffh9gtGB2LoRfSPnJCsq\nE/oh4Jzl5wn9tkqJCCGOCCGeEEK8tdQdhBDv1+9zZHp6uoqHrp1I0M/n3nWAP/3F/XU/1ifuvJ6/\nuvvVa+yYg7t7mF1Jc2JSi3Qml5Kks3l29norEWuwb7gLKeH5C4vmba3WotjAsB+MiF71uakcq41n\nVJ5d2a8Jfb5M5c1KSiVjG4kb1+MjUsoDwK8AnxFCXFl8BynlvVLKA1LKA/39/S4sSePQaD9X9NUv\nunu2xji4e+3waONNcPhlbXOWUXHT6F2x5bDOkzVYTGRbruIGVleOgLJuqsHaE+pW/TU+OhAjns5x\nYaH00PlEOosQrJn5oHCHSs76eWCH5edh/baKkFKe1/89BTwC3FjF+pqa7V1t7NkaM2uNjRYDXrVu\nemNhhrrbeNbi07dqRF885HpyMUV7yL+msZ1iLdGQHyFgd1+7OWB+VLc/y9k3K+kc7aGA54oQNguV\nCP1TwKgQYpcQIgTcBVRUPSOE2CKECOvf9wGvBV6odbHNyKHRPn70yhzJTI4zcyv4fWJVf2qvsX+4\nyywJPXFpiZPTyy05Wm9Le4iAT/Ct5y+Rz0tVQ18FQggGu9r42b0D5m2jW2NAeaGPp7MNa8utqEDo\npZRZ4EPAw8CLwFellM8LIT4hhLgDQAjxGiHEBPDLwGeFEM/rh18LHBFCPAt8H/hTKeWmEvrbRvtJ\nZfMcOX2Zs3MJBrsjBD1cwbJvuIszs3FOz6zwvi8eoSMS5Ld/ZrTRy7KdWDjAR998Dd96YZL/+r1x\nphaTKhFbBf/8W7fyO2+82vx5S3uI3vYQY2VaIcTTuU05XcorVHSdKqV8EHiw6LaPW75/Cs3SKT7u\nB8C+OtfY1Bzc3UPQLzg8Ps3Z2RVGPLYjtpj9Q90A3P25J5leSnH/r9/Ctq7WjHTfc+suXri4yF98\n52XCAZ85jUyxMVva127427M1VrbEciW1OefFegV15h0mGgpw08gWDr88w4WFBG/Zt73RS1qXfXpC\n9vx8gk/90n5evXNLg1fkHEII/tMv7OPU9ArPnJtXm6XqZHQgxv9+5gJSSoQQPPTcJZ58ZRaAFy8u\nsr1FA4ZmQAm9Cxwa7edTD58AvFtxY9AVDfKGa7dy7fZOfvnAjo0PaHIiQT+ffedNvPcLR7h5V+Pa\nyLYCo1s7WEpmmVpK8dz5BX7jvqNEAn4Cfi0B+/Ml+kUp3EEJvQscGu0rCL1HK26sfO5dr9n4Ti3E\nQGeEf/qtWxu9jKZnj56Qfei5S3zq4RNcN9jJ1379J1US1gN4NyvYQlw32MUWfTJVoweOKBROYVTe\n/NE/PU8k6Ofedx5QIu8RlNC7gN8nzNbIIx7dFatQ1Et/R5jOSICAT/A373i1p8uINxvKunGJD7zu\nSvYOdqoNOYqWRQjBv7v9GrZ2hDlwhcp3eAmlOi5x/VBXyQlWCkUr8U7LXGWFd1DWjUKhULQ4SugV\nCoWixVFCr1AoFC2OEnqFQqFocZTQKxQKRYujhF6hUChaHCX0CoVC0eIooVcoFIoWR0hZephvoxBC\nTANnqjysD5hxYDm14rX1gPfW5LX1gPfW5LX1gPfW5LX1QOPWNCKlLDl023NCXwtCiCP6AHJP4LX1\ngPfW5LX1gPfW5LX1gPfW5LX1gDfXpKwbhUKhaHGU0CsUCkWL0ypCf2+jF1CE19YD3luT19YD3luT\n19YD3luT19YDHlxTS3j0CoVCoShPq0T0CoVCoSiDEnqFQqFodaSUrn0BtwMngHHgo5bbP6TfJoG+\ndY7fBTyp3/crQEi//Tbgx0AW+KVqnl+/7RSQRKt9/QoQcnFNnwemgOeK1nhZv/0Y8L+Af1fnej4C\nvKA/3nfRam4bfY4qXdOqc2RZ0xyQBi7q56jbhjV9ADgOPAM8Buwtc/y7gDH9612W83YOuKQ/7l+6\nuJ6HgHngn4vO0aJ+ji7p5zFY75osv3+b/hgHGnmOqliPa+cIeDcwrf/dngHeW6Umrvt/rfbLMVEv\n8R/yAyeB3Wgi8azxogVuBK4ATm9wUr8K3KV//zfAb+jfXwHsB75IGVEt8/zX67d9A7hbv+0rwG+4\nsSb9frcBrwaeK1rjW4xzBPwZ8N/rXM/rgaj+/W8AX/HAOdpwTcXnqGidvwq06Wv6nH6e6l1Tp+U+\ndwAPlTi2B+2DrwfYon//in7enkITtr3AN9EEw9H16L/7GeDn0UXMco7+L8vf8ht2/N30nzuAR4En\nKCGsbp6jStbj9jlCE/r/Vu64dd5vezf6v9by5aZ1czMwLqU8JaVMA/cDdwJIKZ+WUp5e72AhhAB+\nGvi6ftMXgLfqx5+WUh4D8lU+/wfRPjEPoonX/WhR4ltdWhNSykf15yxe44MUztETaJ/o9azn+1LK\nuH77E8BwiYdw+xxVsqbic2Rd5xellAl9TWFg2IY1LVru2o4W0RXzJuDbUso5KeVltDfoIpBAE5zP\no/3dvgjsc2E9SCm/CyxZbjLO0ectf0uJDedI54/RPliTZR7CtXNU4XoacY42oqQm2vC4a3BT6IfQ\nLtkMJvTbKqUXmJdSZms8vtTzX4FmCRiPO4EWIVb6uPWuqZI1DqFFHN+0cT3vKfN4jTxH5dZUilLr\nvLWK49ddkxDig0KIk8AngQ9X8PxJ/WtIf6wJy/eVnKd611OK4jVeRBOWhyo8vuyahBCvBnZIKb9R\nxfM7do4qXE8la7TtHOm8TQhxTAjxdSHEjgqe3zjebl1Rydgm4CY0n/8+Ox5MCPEO4ADwKTsezw5s\nWNMdaFdOtpwjKeU9Usorgd8DPmbHY3pgPe8CLkgpD9ezFiGED/g08Dv1PI5d2LweW86Rzj8BV0gp\n9wPfRovKG4abQn8esH6qDeu3lUUI8bAQ4hkhxOeAWaBbCBGo9PgKnv80sNXyuMNol5ZlH9fmNW20\nxjuAQeBuqZt19axHCPEG4A+AO6SUqQqe3/FzVMGaSmGuUwjxbrQo7AvlzlG1a7JwP6UvmYvPU0T/\nOq8/1rDl+5Lnyeb1lMJ6jv4Q7W/41fUOqHBNHWh5m0eEEKeBW4AHhBDFvV3cOkeVrqcUTp0jpJSz\nltfz59ACtrLPX3S83briajI2gJaQ2UUh8XBd0X1Os37i42usTlD8ZtHv/wflk7Glnn+/fltxovE3\n3ViT5T5XoCVjrWv8V2iXurfacY7QkksngdEq/0aOnaNK1lR8jorW+S60qp3n/k87Z8zSQBCE0ddZ\na2eplZDa3k6w8yeovbUg2NoqWFjYW9hZCwkkkCA2FmlESSOKhaUIRtBi5shyeLiXnIss34NtNju7\n387dTmBnuKbepVALlri7+cF2AUssznsb+XpLTBKNLewqaeOv9QS/rzFJNBY+2gP6WGVTo+fN+ztU\nJ2OT+ChGT2ofAYvBmE1gEHneWrF7rdOmNpxqMaskucMO937Qv4vdQ30CT8BZhf0ycI0lBy+AOe9f\ndfs37N9wGLu+942woPpazJtQ0zl2Nzj28UeucYyVghXlWb0Z9VwBL8F8l//AR7Gayj7acU0fvvaz\n2582oOkYGPp8bUoHP7Dfdtt7YCvw26Pv6QE4Saini5Xzvft6667py/1W+OhgVk2lMR2qq1yS+KiG\nnmQ+Ag79ud36c1upGRN/3Wudpk8gCCFE5igZK4QQmaNAL4QQmaNAL4QQmaNAL4QQmaNAL4QQmaNA\nL4QQmaNAL4QQmfMNYS6AyTA/7D4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G46Jt2rLC6We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cdf = pd.Series(df['Concentration'].values)\n",
        "width = 25\n",
        "lag1 = cdf.shift(1)\n",
        "lag3 = cdf.shift(width - 1)\n",
        "window = lag3.rolling(window=width)\n",
        "means = window.mean()\n",
        "dataframe = pd.concat([means, lag1, cdf], axis=1)\n",
        "dataframe.columns = ['mean', 't-1', 't+1']\n",
        "#dataframe.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPci3iU4ETBU",
        "colab_type": "code",
        "outputId": "3d4bf6df-2a5e-42cf-8521-26ae354ff33a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "dataframe.head()\n",
        "plt.plot([i for i in range(len(dataframe['mean']))][0:100],dataframe['mean'][0:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f00c8e7bbe0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSnk4DXqllPJwGvRKKeXh/j8Gt9mswOpD5AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6UR3UlGMwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "data = np.array(dataframe['mean'][48:])\n",
        "data = preprocessing.scale(data)\n",
        "n_inputs=3\n",
        "data_final = np.column_stack([data[2:], data[1:][1:], data[2:][0:]]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq0cdqawKt1g",
        "colab_type": "code",
        "outputId": "d9e7dce2-ef95-4392-fc55-8e498981fe8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640578,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N98bL0G9JWbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data_final[:-1]\n",
        "y = data_final.T[0].T[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3oQWjRiJ0Mz",
        "colab_type": "code",
        "outputId": "1659254a-6a54-4bf3-a6f4-242c80124a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((640575, 3), (640575,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3_i-D_1MYQS",
        "colab_type": "text"
      },
      "source": [
        "##Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvtZ7NLuhOan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import randn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8j2l965W6oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=1000\n",
        "args['test_batch_size']=1000\n",
        "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=10\n",
        "args['cuda']=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FICEO8tME0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = torch.from_numpy(x)\n",
        "target = torch.from_numpy(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dMilcLwlPL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RNN, self).__init__()\n",
        "    self.computing_h = nn.Linear(4, 2)\n",
        "    self.computing_y = nn.Linear(4, 1)\n",
        "    self.final_output = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x_current, h_prev, y_prev):\n",
        "        self.x_current = x_current\n",
        "        self.h_prev = h_prev\n",
        "        self.y_prev = y_prev\n",
        "        self.combined = torch.cat([self.x_current.float(),self.h_prev[0].float(),self.y_prev[0].float()], axis=0).unsqueeze(1)\n",
        "        self.h_new = F.tanh(self.computing_h(self.combined.T))\n",
        "        self.y_new = F.tanh(self.computing_y(torch.cat([self.x_current.float(),self.h_new[0].float(),self.y_prev[0].float()], axis=0)))\n",
        "        self.output = F.relu(self.final_output(self.y_new))\n",
        "        return self.h_new, self.output\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVT-6K_cYmH",
        "colab_type": "text"
      },
      "source": [
        "Now, with the help of gradient descent we calculate the errors in weights, then correct them and subsequently compute the final weights.\n",
        "This is done with the help of the loss function. This loss function is the cross entropy loss which is given by L=-ln(p) = -ln(softmax(p))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxxc9qrTaUw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    y_new = 0\n",
        "    global data\n",
        "    global target\n",
        "    for epoch in range(1,epoch+1):\n",
        "      if args['cuda']:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "      optimizer.zero_grad()\n",
        "      for i,k in zip(data,target):\n",
        "        x, y_final = Variable(i), Variable(k)\n",
        "        h_new = torch.zeros(1,2)\n",
        "        y_new = torch.zeros(1,1)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        for j in range(3):\n",
        "          h_new, output = model(x[j].unsqueeze(0), h_new, y_new)\n",
        "          # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "          loss = torch.mean((output-target)**2)\n",
        "          # print(loss)\n",
        "          #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if epoch % 1 == 0:\n",
        "          print('Epoch: {}/{}.............'.format(epoch, 10), end=' ')\n",
        "          print(\"Loss: {:.4f}\".format(loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIMQ9MEpcDud",
        "colab_type": "text"
      },
      "source": [
        "We have,\n",
        "y = Why​*h​ + by  \n",
        "With Gradient descent we need to calculate the derivative of the loss function with respect to all the 5 weights involved. ​"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGPJ1226aSk0",
        "colab_type": "code",
        "outputId": "54b22568-92e5-4341-d6f6-15f20f62317c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = RNN()\n",
        "train(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10............. Loss: 1.1339\n",
            "Epoch: 1/10............. Loss: 1.1308\n",
            "Epoch: 1/10............. Loss: 1.1283\n",
            "Epoch: 1/10............. Loss: 1.1287\n",
            "Epoch: 1/10............. Loss: 1.1343\n",
            "Epoch: 1/10............. Loss: 1.1310\n",
            "Epoch: 1/10............. Loss: 1.1332\n",
            "Epoch: 1/10............. Loss: 1.1361\n",
            "Epoch: 1/10............. Loss: 1.1389\n",
            "Epoch: 1/10............. Loss: 1.1394\n",
            "Epoch: 1/10............. Loss: 1.1392\n",
            "Epoch: 1/10............. Loss: 1.1394\n",
            "Epoch: 1/10............. Loss: 1.1429\n",
            "Epoch: 1/10............. Loss: 1.1436\n",
            "Epoch: 1/10............. Loss: 1.1415\n",
            "Epoch: 1/10............. Loss: 1.1365\n",
            "Epoch: 1/10............. Loss: 1.1341\n",
            "Epoch: 1/10............. Loss: 1.1290\n",
            "Epoch: 1/10............. Loss: 1.1242\n",
            "Epoch: 1/10............. Loss: 1.1172\n",
            "Epoch: 1/10............. Loss: 1.1091\n",
            "Epoch: 1/10............. Loss: 1.1061\n",
            "Epoch: 1/10............. Loss: 1.1032\n",
            "Epoch: 1/10............. Loss: 1.1015\n",
            "Epoch: 1/10............. Loss: 1.1014\n",
            "Epoch: 1/10............. Loss: 1.1019\n",
            "Epoch: 1/10............. Loss: 1.1029\n",
            "Epoch: 1/10............. Loss: 1.1094\n",
            "Epoch: 1/10............. Loss: 1.1101\n",
            "Epoch: 1/10............. Loss: 1.1040\n",
            "Epoch: 1/10............. Loss: 1.1035\n",
            "Epoch: 1/10............. Loss: 1.1031\n",
            "Epoch: 1/10............. Loss: 1.1014\n",
            "Epoch: 1/10............. Loss: 1.1004\n",
            "Epoch: 1/10............. Loss: 1.1036\n",
            "Epoch: 1/10............. Loss: 1.1063\n",
            "Epoch: 1/10............. Loss: 1.1097\n",
            "Epoch: 1/10............. Loss: 1.1120\n",
            "Epoch: 1/10............. Loss: 1.1157\n",
            "Epoch: 1/10............. Loss: 1.1156\n",
            "Epoch: 1/10............. Loss: 1.1141\n",
            "Epoch: 1/10............. Loss: 1.1113\n",
            "Epoch: 1/10............. Loss: 1.1107\n",
            "Epoch: 1/10............. Loss: 1.1085\n",
            "Epoch: 1/10............. Loss: 1.1102\n",
            "Epoch: 1/10............. Loss: 1.1084\n",
            "Epoch: 1/10............. Loss: 1.1054\n",
            "Epoch: 1/10............. Loss: 1.1015\n",
            "Epoch: 1/10............. Loss: 1.0973\n",
            "Epoch: 1/10............. Loss: 1.0921\n",
            "Epoch: 1/10............. Loss: 1.0904\n",
            "Epoch: 1/10............. Loss: 1.0972\n",
            "Epoch: 1/10............. Loss: 1.0943\n",
            "Epoch: 1/10............. Loss: 1.0965\n",
            "Epoch: 1/10............. Loss: 1.0978\n",
            "Epoch: 1/10............. Loss: 1.0941\n",
            "Epoch: 1/10............. Loss: 1.0892\n",
            "Epoch: 1/10............. Loss: 1.0854\n",
            "Epoch: 1/10............. Loss: 1.0812\n",
            "Epoch: 1/10............. Loss: 1.0766\n",
            "Epoch: 1/10............. Loss: 1.0694\n",
            "Epoch: 1/10............. Loss: 1.0638\n",
            "Epoch: 1/10............. Loss: 1.0577\n",
            "Epoch: 1/10............. Loss: 1.0525\n",
            "Epoch: 1/10............. Loss: 1.0488\n",
            "Epoch: 1/10............. Loss: 1.0466\n",
            "Epoch: 1/10............. Loss: 1.0476\n",
            "Epoch: 1/10............. Loss: 1.0452\n",
            "Epoch: 1/10............. Loss: 1.0440\n",
            "Epoch: 1/10............. Loss: 1.0418\n",
            "Epoch: 1/10............. Loss: 1.0408\n",
            "Epoch: 1/10............. Loss: 1.0408\n",
            "Epoch: 1/10............. Loss: 1.0429\n",
            "Epoch: 1/10............. Loss: 1.0440\n",
            "Epoch: 1/10............. Loss: 1.0465\n",
            "Epoch: 1/10............. Loss: 1.0555\n",
            "Epoch: 1/10............. Loss: 1.0513\n",
            "Epoch: 1/10............. Loss: 1.0484\n",
            "Epoch: 1/10............. Loss: 1.0435\n",
            "Epoch: 1/10............. Loss: 1.0381\n",
            "Epoch: 1/10............. Loss: 1.0369\n",
            "Epoch: 1/10............. Loss: 1.0327\n",
            "Epoch: 1/10............. Loss: 1.0286\n",
            "Epoch: 1/10............. Loss: 1.0282\n",
            "Epoch: 1/10............. Loss: 1.0276\n",
            "Epoch: 1/10............. Loss: 1.0292\n",
            "Epoch: 1/10............. Loss: 1.0310\n",
            "Epoch: 1/10............. Loss: 1.0318\n",
            "Epoch: 1/10............. Loss: 1.0307\n",
            "Epoch: 1/10............. Loss: 1.0318\n",
            "Epoch: 1/10............. Loss: 1.0315\n",
            "Epoch: 1/10............. Loss: 1.0282\n",
            "Epoch: 1/10............. Loss: 1.0295\n",
            "Epoch: 1/10............. Loss: 1.0302\n",
            "Epoch: 1/10............. Loss: 1.0320\n",
            "Epoch: 1/10............. Loss: 1.0343\n",
            "Epoch: 1/10............. Loss: 1.0352\n",
            "Epoch: 1/10............. Loss: 1.0337\n",
            "Epoch: 1/10............. Loss: 1.0396\n",
            "Epoch: 1/10............. Loss: 1.0356\n",
            "Epoch: 1/10............. Loss: 1.0237\n",
            "Epoch: 1/10............. Loss: 1.0198\n",
            "Epoch: 1/10............. Loss: 1.0192\n",
            "Epoch: 1/10............. Loss: 1.0184\n",
            "Epoch: 1/10............. Loss: 1.0205\n",
            "Epoch: 1/10............. Loss: 1.0216\n",
            "Epoch: 1/10............. Loss: 1.0279\n",
            "Epoch: 1/10............. Loss: 1.0309\n",
            "Epoch: 1/10............. Loss: 1.0306\n",
            "Epoch: 1/10............. Loss: 1.0318\n",
            "Epoch: 1/10............. Loss: 1.0321\n",
            "Epoch: 1/10............. Loss: 1.0303\n",
            "Epoch: 1/10............. Loss: 1.0286\n",
            "Epoch: 1/10............. Loss: 1.0281\n",
            "Epoch: 1/10............. Loss: 1.0246\n",
            "Epoch: 1/10............. Loss: 1.0241\n",
            "Epoch: 1/10............. Loss: 1.0228\n",
            "Epoch: 1/10............. Loss: 1.0202\n",
            "Epoch: 1/10............. Loss: 1.0168\n",
            "Epoch: 1/10............. Loss: 1.0138\n",
            "Epoch: 1/10............. Loss: 1.0124\n",
            "Epoch: 1/10............. Loss: 1.0118\n",
            "Epoch: 1/10............. Loss: 1.0177\n",
            "Epoch: 1/10............. Loss: 1.0151\n",
            "Epoch: 1/10............. Loss: 1.0175\n",
            "Epoch: 1/10............. Loss: 1.0176\n",
            "Epoch: 1/10............. Loss: 1.0140\n",
            "Epoch: 1/10............. Loss: 1.0096\n",
            "Epoch: 1/10............. Loss: 1.0063\n",
            "Epoch: 1/10............. Loss: 1.0032\n",
            "Epoch: 1/10............. Loss: 1.0013\n",
            "Epoch: 1/10............. Loss: 1.0003\n",
            "Epoch: 1/10............. Loss: 1.0001\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0027\n",
            "Epoch: 1/10............. Loss: 1.0087\n",
            "Epoch: 1/10............. Loss: 1.0145\n",
            "Epoch: 1/10............. Loss: 1.0139\n",
            "Epoch: 1/10............. Loss: 1.0095\n",
            "Epoch: 1/10............. Loss: 1.0113\n",
            "Epoch: 1/10............. Loss: 1.0118\n",
            "Epoch: 1/10............. Loss: 1.0073\n",
            "Epoch: 1/10............. Loss: 1.0093\n",
            "Epoch: 1/10............. Loss: 1.0116\n",
            "Epoch: 1/10............. Loss: 1.0243\n",
            "Epoch: 1/10............. Loss: 1.0412\n",
            "Epoch: 1/10............. Loss: 1.0494\n",
            "Epoch: 1/10............. Loss: 1.0305\n",
            "Epoch: 1/10............. Loss: 1.0548\n",
            "Epoch: 1/10............. Loss: 1.0940\n",
            "Epoch: 1/10............. Loss: 1.1393\n",
            "Epoch: 1/10............. Loss: 1.1774\n",
            "Epoch: 1/10............. Loss: 1.2218\n",
            "Epoch: 1/10............. Loss: 1.2198\n",
            "Epoch: 1/10............. Loss: 1.1696\n",
            "Epoch: 1/10............. Loss: 1.1315\n",
            "Epoch: 1/10............. Loss: 1.1057\n",
            "Epoch: 1/10............. Loss: 1.0742\n",
            "Epoch: 1/10............. Loss: 1.0368\n",
            "Epoch: 1/10............. Loss: 1.0104\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n",
            "Epoch: 1/10............. Loss: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7b8d2c287329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-266296354617>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mh_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0;31m# Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m           \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0;31m#dloss/dx for every Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7G0Ho2ynuIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t  = torch.cat([model.x_current.float(),model.h_prev[0].float(),model.y_prev[0].float()], axis=0)\n",
        "t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmVSTezWfHzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cat([model.x_current.float(),model.h_new.float(),model.y_prev[0].float()], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msghPzt1kwbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.h_new[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FhxW1ZXhS5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cat([self.x_current.float(),self.h_prev[0].float(),self.y_prev[0].float()], axis=0).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsIhX4RhhrGt",
        "colab_type": "code",
        "outputId": "6f8a7a36-9cd3-49fd-8374-5f9f9711ac73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "model.eval()\n",
        "d = torch.Tensor([43,44,45])\n",
        "h_new=torch.Tensor([0,0])\n",
        "y_new=torch.Tensor([0])\n",
        "for j in range(3):\n",
        "  h_new, output = model(d[j].unsqueeze(0), h_new, y_new)\n",
        "          # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "  print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-216-ab4c884ef2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mh_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m           \u001b[0;31m# Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-201-4e9e48915182>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_current, h_prev, y_prev)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputing_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputing_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 1) cannot be concatenated"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHpB5j4pnv45",
        "colab_type": "code",
        "outputId": "5bfb19c0-e92b-4d7c-863c-b91fbe41f0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.x_current.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgEyMgKbpFDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}